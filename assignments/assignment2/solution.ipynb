{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11310c5e",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1. Professional Data Ingestion\n",
    "data = pd.read_csv('data/portland_housing.csv')\n",
    "X = data['size_sqft'].values\n",
    "y = data['price_k'].values\n",
    "m = len(y) # Total training examples [cite: 524]\n",
    "\n",
    "# 2. Preprocessing & Feature Scaling\n",
    "# Normalizing features to ensure stable Gradient Descent convergence\n",
    "X_norm = (X - np.mean(X)) / np.std(X)\n",
    "X_bias = np.c_[np.ones((m, 1)), X_norm] # Adding intercept term x0 = 1 [cite: 548]\n",
    "\n",
    "# 3. Batch Gradient Descent Implementation\n",
    "def compute_cost(X, y, theta):\n",
    "    \"\"\"Calculates Mean Squared Error J(theta)[cite: 581].\"\"\"\n",
    "    return (1/(2*m)) * np.sum((X.dot(theta) - y)**2)\n",
    "\n",
    "def batch_gradient_descent(X, y, theta, alpha, iterations):\n",
    "    \"\"\"Iteratively updates theta via the LMS rule [cite: 651-654].\"\"\"\n",
    "    cost_history = []\n",
    "    for i in range(iterations):\n",
    "        gradients = (1/m) * X.T.dot(X.dot(theta) - y)\n",
    "        theta = theta - alpha * gradients # Update rule [cite: 618-619, 743]\n",
    "        cost_history.append(compute_cost(X, y, theta))\n",
    "    return theta, cost_history\n",
    "\n",
    "# 4. Analytical Solution: Normal Equation\n",
    "# theta = (X^T X)^-1 X^T y [cite: 834]\n",
    "theta_normal = np.linalg.inv(X_bias.T.dot(X_bias)).dot(X_bias.T).dot(y)\n",
    "\n",
    "# 5. Training and Comparison\n",
    "alpha = 0.01\n",
    "iterations = 1500\n",
    "theta_init = np.zeros(2)\n",
    "theta_gd, history = batch_gradient_descent(X_bias, y, theta_init, alpha, iterations)\n",
    "\n",
    "print(f\"Gradient Descent Result: {theta_gd}\")\n",
    "print(f\"Normal Equation Result: {theta_normal}\")\n",
    "\n",
    "# Convergence Visualization\n",
    "plt.plot(history)\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Cost J(theta)')\n",
    "plt.title('Convergence Analysis')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
