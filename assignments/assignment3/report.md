# Technical Report: Non-parametric Regression and Binary Classification

## Objective
This implementation covers the transition from continuous regression to
discrete classification, focusing on **Locally Weighted Regression (LWR)**
and **Logistic Regression** for autonomous decision-making.

## Methodology

- **Locally Weighted Regression**:
  Explored a non-parametric approach where predictions are generated by
  fitting a local linear model around query points using a Gaussian-like
  weight function.

- **Logistic Regression**:
  Implemented binary classification using the sigmoid function to map
  linear outputs into the probability space [0, 1].

- **Gradient Ascent**:
  Maximized the log-likelihood of the parameters to converge on optimal
  weights for obstacle detection.

## Engineering Insights

- **Parametric vs. Non-parametric**:
  While LWR provides a flexible, non-linear fit, its O(m) prediction
  complexity makes it computationally expensive for real-time systems
  without efficiency optimizations such as KD-trees.

- **Probabilistic Soundness**:
  Logistic Regression is justified by the binomial distribution of binary
  labels, providing a more robust framework than linear regression for
  classification tasks.

## Conclusion
The current model successfully classifies environmental inputs into binary
states (Obstacle / Clear). This serves as the foundation for Perceptron and
Neural Network architectures explored in subsequent modules.
