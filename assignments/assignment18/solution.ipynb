{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4fb8eb7",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# 1. System Parameters (Linear Dynamics)\n",
    "# s_{t+1} = A*s_t + B*a_t\n",
    "A = np.array([[1.1, 0], [0, 1.0]])\n",
    "B = np.array([[0.5, 0], [0, 1.0]])\n",
    "U = np.eye(2)    # State cost\n",
    "V = 0.1 * np.eye(2) # Action cost\n",
    "T = 10           # Time horizon\n",
    "\n",
    "# 2. LQR Solver via Riccati Recursion\n",
    "def solve_lqr(A, B, U, V, T):\n",
    "    # Initialize Phi at terminal time T [cite: 4098]\n",
    "    phi = -U\n",
    "    phis = [phi]\n",
    "    Ls = []\n",
    "    \n",
    "    # Backward recursion for t = T-1 down to 0 [cite: 4154]\n",
    "    for t in range(T-1, -1, -1):\n",
    "        # Calculate optimal gain matrix L_t [cite: 4120-4123]\n",
    "        # L = -(B^T * Phi * B + V)^-1 * B^T * Phi * A\n",
    "        term_inv = np.linalg.inv(B.T.dot(phi).dot(B) - V)\n",
    "        L = term_inv.dot(B.T).dot(phi).dot(A)\n",
    "        \n",
    "        # Update Phi for time t using Discrete-Time Riccati Equation\n",
    "        # Phi_t = A^T * Phi_{t+1} * (A + B*L) - U\n",
    "        phi = A.T.dot(phi).dot(A + B.dot(L)) - U\n",
    "        \n",
    "        phis.append(phi)\n",
    "        Ls.append(L)\n",
    "        \n",
    "    return Ls[::-1], phis[::-1]\n",
    "\n",
    "# 3. Execution\n",
    "gains, value_matrices = solve_lqr(A, B, U, V, T)\n",
    "\n",
    "# 4. Controller Inference\n",
    "current_state = np.array([1.0, 0.5]) # Initial deviation\n",
    "optimal_action = gains[0].dot(current_state)\n",
    "\n",
    "print(f\"Optimal Gain Matrix (L_0):\\n{gains[0]}\")\n",
    "print(f\"Optimal Action for current state: {optimal_action}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
